\documentclass[twoside,english]{uiofysmaster}

%\usepackage[utf8]{inputenc} % Riktig tegnsett
\usepackage{babel} 
\usepackage{url}
\usepackage{units}
\usepackage{lipsum}
\usepackage{graphicx}  
\usepackage{subcaption} 
\usepackage{color}
%\usepackage{amsmath}  
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{braket} 
\usepackage{multicol}
%\usepackage{listings}  
\usepackage{amsfonts}
%\usepackage{siunitx}
\usepackage{float}

\usepackage{tabularx}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
\newcolumntype{L}{>{\raggedright\arraybackslash}X}
\usepackage{booktabs}   

\usepackage{tikz}
\usepackage{tikz-3dplot}
%\usepackage{xcolor}
\usepackage{xifthen}
\usepackage{caption}

\usepackage{HASstyle}

\setlength{\parskip}{0em}
% ---------Custom commands-------------
\newcommand\lr[1]{\left(#1\right)} 


%-------------- Colors -----------------
\definecolor{LightBlue}{rgb}{0.8, 0.8, 0.95}
\definecolor{editColor}{rgb}{0.5, 0.0, 0.0}


\definecolor{p0}{HTML}{D7DFC0}
\definecolor{p1}{HTML}{AECFA2}
\definecolor{p2}{HTML}{82BC92}
\definecolor{p3}{HTML}{5FA38E}
\definecolor{p4}{HTML}{49848B}
\definecolor{p5}{HTML}{3F5F7F}
\definecolor{p6}{HTML}{383D65}
\definecolor{p7}{HTML}{2C1E3E}

\hypersetup{
	colorlinks = true,
	linkbordercolor = white,
%	linkcolor = blue,
	urlcolor  = p5,
	citecolor = p5,
	citebordercolor= white,
}








\author{Filip Henrik Larsen}
\title{Title of the master thesis}
\date{May 2017}

\begin{document}

\maketitle

\begin{abstract}
This is an abstract text.
\end{abstract}

\begin{dedication}
  To someone
  \\\vspace{12pt}
  This is a dedication to my cat.
\end{dedication}

\begin{acknowledgements}
  Flora Joelle Larsen\\*
  Anders Malthe-Sørenssen \\*
  Anders Hafreager \\*
  Henrik Sveinson \\*
  Kjetil
\end{acknowledgements}
{
\hypersetup{linkcolor = black}
\tableofcontents
}
\chapter{Introduction}

Why is the subject of this thesis of any interest?\\
What is our take on the problem?\\
What do we hope to accomplish?\\
How will this be of any contribution to anything?\\
How is the thesis laid out?


\chapter{Molecular dynamics}
Molecular dynamics is a method that uses Newton’s equations of motion to simulate the movement of interacting atoms. 
Each atom is treated as a point particle with a mass, and the interaction between them is described by a force field. 
Molecular dynamics aid our understanding of macroscopic phenomena by giving us insight in microscopic effects and behavior. 
It can be used if an experiment is to difficult, dangerous or expensive to do otherwise, for instance experiments at extreme temperatures or pressure. 
The areas of application are wide, and it has become a very popular field in material science, biochemistry and biophysics.

In this chapter we will present the basic principals of molecular dynamics, including essential algorithms, common methods and efficiency improvements.

%Molecular dynamics simulations are computationally expensive. And often scientists must balance statistical precision and CPU time. Technological improvements have provided us the ability to simulate larger systems and/or at longer time frames than ever before. 

\section{Time-integration}
The evolution of particles position and velocity is carried out through time integration.
In molecular dynamics, atoms movement is governed by Newton's second law
\begin{equation}
	\sum_{i=1}^{N}\vec{F_i} = m_i\vec{a_i}
\end{equation}
Theoretically, the computation of particles movement is easy to assimilate.
We know that acceleration is the derivative of velocity, which in turn is the derivative of position.
Thus we should be able to retrieve the velocities and positions using time-integration of the acceleration.
\begin{align}
	\vec{v_i}(t) &= \vec{v_i}(0) + \int_{0}^{t}\vec{a_i}(t) dt \\
	\vec{r_i}(t) &= \vec{r_i}(0) + \int_{0}^{t}\vec{v_i}(t) dt
\end{align}
When solving an integral numerically, we're forced to discretize the problem and use an approximation method.
This is done by dividing the domain into steps of size $\Delta t$ and approximate the area of the function inside each such partition.
Typically, the error of the approximation decreases when reducing the time step $\Delta t$. 
However, a smaller step length leads to higher computational expense, and may limit the size or time-frame we are able to compute. 
These are common considerations when doing computational research. 
One has to balance precision, size/time-frame, time and expense. 
It is therefore very important to choose a numerical scheme that has a satisfying level of precision as well as speed. 

There are numerous numerical integration methods, but not all these have properties that are desirable for molecular dynamics simulation. 
The most fundamental features the scheme should have are high precision, computationally cheap, good energy conservation, reversibility and be deterministic.
Conservation of energy is fundamental in physics, and in order to simulate the micro-canonical ensemble (NVE), the integration method cannot have an energy drift.
The dynamics should be reversible, meaning one should be able to simulate the system in the opposite direction in time, and arrive at past states.
It should be deterministic in the sense that by the information about a specific state $(r(t_0), v(t_0))$ one should be able to compute the the state at any other time $(r(t), v(t))$, be it future of past.
Molecular dynamics simulations are computational expensive, and practically all the work lies in the time-integration loop. More precisely computing the sum of forces on each atom. 
The choice of integration scheme is therefore very important. 
As it turns out, probably the best scheme for the task is also one of the simplest. 

\subsection{Velocity Verlet}
In molecular dynamics the most common scheme for time-integration is the \textit{Velocity Verlet} algorithm, which is a specific type of Verlet integration.
It is derived by taylor expanding the position both one time step forward and one backwards as follows: 
\begin{align}
	r(t+\Delta t) &= r(t) + \frac{\Delta t}{1!}r'(t) + \frac{\Delta t^2}{2!}r''(t) + \frac{\Delta t^3}{3!}r'''(t) + \mathcal{O}(\Delta t^4)\\[1ex]
	r(t-\Delta t) &= r(t) - \frac{\Delta t}{1!}r'(t) + \frac{\Delta t^2}{2!}r''(t) - \frac{\Delta t^3}{3!}r'''(t) + \mathcal{O}(\Delta t^4)
\end{align}
If we add these two together, the odd terms cancel. 
After rearranging, we are left with the very simple verlet algorithm. 
\begin{equation}
r(t+\Delta t) = 2r(t) - r(t-\Delta t) + \Delta t^2r''(t) + \mathcal{O}(\Delta t^4)
\end{equation}
Or written in a compact notation where
\begin{align}
	&\vec{r}^n = r(t)& &\vec{r}^{n\pm 1} = r(t\pm \Delta t)&  &\vec{a}^n = \frac{\partial \vec{v}^n}{\partial t} = \frac{\partial^2 \vec{r}^n}{\partial t ^2}
\end{align}
this can be expressed as
\begin{equation}\label{eq:stromer-verlet}
\vec{r}^{n+1} = 2\vec{r}^n - \vec{r}^{n-1} + \Delta t^2\vec{a}^n ~.
\end{equation}
Notice that we do not rely on information about the velocity in order to predict the next position. 
The algorithm in equation \eqref{eq:stromer-verlet} is known as Strömer-Verlet. 
It's not self-starting, since you need to know the previous and current steps to predict the next. 
Thus, it needs to be initialized in a way, e.g. by using algorithm \eqref{eq:velocity-verlet} for the first step. 
It has a high order truncation error, proportional to $\mathcal{O}(\Delta t^4)$, however it's vulnerable to round-off errors. 
This is because the last term is proportional to $\Delta t^2$, and is potentially much smaller than the other terms.
When trying to add it with the other terms, this may be a source of round-off error \cite{MATINF1100}. 
As a remedy to this problem, the Velocity Verlet algorithm incorporates a second order differential approximation of the velocity.
 \begin{equation}\label{eq:velocity-verlet-velocity}
\vec{v}^n = \frac{ \vec{r}^{n+1}-\vec{r}^{n-1} }{2\Delta t} + \mathcal{O}(\Delta t^2)
\end{equation}
Resulting in 
\begin{align}\label{eq:velocity-verlet}
	\vec{r}^{n+1} &= \vec{r}^n + \Delta t\vec{v}^n + \frac{\Delta t^2}{2}\vec{a}^n\\
	\vec{r}^{n+1} &= \vec{r}^n + \Delta t\lr{\vec{v}^n + \frac{\Delta t}{2}\vec{a}^n}	
\end{align}    
We may recognize the parenthesis as $\vec{v}^{n+1/2}$, leaving us with
\begin{align}
\vec{r}^{n+1} &= \vec{r}^n + \Delta t \vec{v}^{n+1/2}~. \label{eq:velocity-verlet-position-final}
\end{align}  
Next, we taylor expand the velocity and use a first order approximation of the acceleration.
\begin{align}
\vec{v}^{n+1} &= \vec{v}^n + \Delta t \vec{a}^{n} +  \frac{\Delta t^2}{2}\vec{\dot{a}}^n + \mathcal{O}(\Delta t^3)\\
\vec{v}^{n+1} &= \vec{v}^n + \Delta t \vec{a}^{n} +  \frac{\Delta t^2}{2}\frac{\vec{a}^{n+1} - \vec{a}^n}{\Delta t} \\
\vec{v}^{n+1} &= \vec{v}^n + \frac{\Delta t}{2} \lr{\vec{a}^{n+1} + \vec{a}^n} \\
\vec{v}^{n+1} &= \vec{v}^{n+1/2} + \frac{\Delta t}{2} \vec{a}^{n+1} \label{eq:velocity-verlet-velocity-final}
\end{align}
Equations \eqref{eq:velocity-verlet-position-final} and \eqref{eq:velocity-verlet-velocity-final} define the Velocity Verlet algorithms. 
The final Velocity Verlet algorithm is thus:
\savebox\strutbox{$\vphantom{\dfrac{\Delta t}{2}}$}
\begin{align}
\vec{v}^{n+1/2}	 &= \vec{v}^{n} +  \frac{\Delta t}{2}\vec{a}^n\\
\vec{r}^{n+1} &= \vec{r}^n + \Delta t \vec{v}^{n+1/2}	\\
\vec{a}^{n+1} &= -\nabla U(\vec{r}^{n+1})/m\\
\vec{v}^{n+1} &= \vec{v}^{n+1/2} + \frac{\Delta t}{2} \vec{a}^{n+1}
\end{align}
The Velocity Verlet algorithms has the same truncation error as the original, but a lower round-off error. 
This algorithm has good energy conservation, and is symplectic.

SOME MORE





\section{Potentials}
\subsection{Lennard-Jones} \label{Lennard-Jones-section}
One of the simplest and most known potentials is the Lennard-Jones potential. It was first proposed in 1924 by John Edward Lennard-Jones.  It takes the form
\begin{equation}
	V(r) = 4\epsilon\left[\lr{\frac{\theta}{r}}^{12} -  \lr{\frac{\theta}{r}}^6 \right], \label{eq:Lennard-Jones}
\end{equation}
%giving rise to the force distribution 
%\begin{equation}
%F(r) = -\frac{\partial V(r)}{\partial r} = \frac{24\epsilon}{r}\left[2\lr{\frac{\theta}{r}}^{12} - \lr{\frac{\theta}{r}}^{6}\right], \label{eq:Lennard-Jones}
%\end{equation}
where the first term represents Pauli repulsion due to overlapping electron orbitals, and the last represents the van der Waal force. 
The constant $\theta$ express the distance at which the inter-atomic potential is zero, while $\epsilon$ is the depth of the well. 
$r$ is of course the inter-atomic distance. 
A plot of the potential is shown in figure \ref{fig:Lennard-Jones}.
The inter-atomic distance at which the potential is at it's minimum can easily be shown to be $r=2^{1/6}\theta$. 

\begin{figure}[H]
	\centering{
		\def\svgwidth{\linewidth}
		\input{figures/potentials/LJ.pdf_tex}
		\caption{Lennard-Jones potential as function of inter-atomic distance, $r$, in units of $\theta$. }
		\label{fig:Lennard-Jones}
	}
\end{figure}

Since the potential only account for the Pauli repulsion and van der Waal forces, its applicability is limited to systems consisting of neutral atoms or molecules, where there are no bonds present. It would suffice for studying noble gases, for instance, but that quickly becomes quite dull. 


 
\subsection{Stillinger-Weber}

\subsection{Vashishta}
The Vashishta potential consists of two terms that represent two- and three-body interactions respectively. These incorporate physical effects such as steric repulsion, coulomb interaction, dipole interaction, Van der Waal interaction and energy related to covalent bonds. It can be expressed as

\begin{equation}
V = \sum_{i<j} V_{ij}^{(2)}(r_{ij}) + \sum_{i<j<k} V_{ijk}^{(3)}(\vec{r}_{ij}, \vec{r}_{ik}) , \label{vashistaTwoTerm}
\end{equation}

\noindent
where $\vec{r}_i$ represents the position of the i-th atom, $\vec{r}_{ij} = \vec{r}_j - \vec{r}_i$, and $r_{ij} = |\vec{r}_{ij}|$ is the distance between atom $i$ and atom $j$.
The two-body term, denoted by superscript $(2)$, sums over all atoms $j$ within a cutoff range $r_c$ from atom $i$, and is given as

\begin{equation}
	 V_{ij}^{(2)}(r) = 
	 \frac{H_{ij}}{\displaystyle r^{\eta_{ij}}} +
	 \frac{Z_iZ_j}{r}e^{-r/r_{1s}} -
	 \frac{D_{ij}}{2r^4}e^{-r/r_{4s}} - 
	 \frac{W_{ij}}{r^6}.
\end{equation}

\noindent 
where $H_{ij}$ and $\eta_{ij}$ are the strength and exponent of the steric repulsion respectively, $Z_i$ is the effective charge of atom $i$, $r_{1s}$ and $r_{4s}$ are screening lengths for the coulomb and dipole interaction respectively, $D_{ij}$ is the strength of the dipole interaction, and $W_{ij}$ is the strength of the Van der Waal interaction.

The three-body term of the potential, denoted by superscript $(3)$, sums over all atoms $j$ and $k$ , that are covalently bonded to atom $i$, within a cutoff range of $r_0$, and is expressed as
\begin{equation}
	V_{ijk}^{(3)}(\vec{r}_{ij}, \vec{r}_{ik}) = 
	B_{ijk} \exp\lr{\frac{\xi}{r_{ij}-r_0} + \frac{\xi}{r_{ik}-r_0}}
	\frac{\lr{\cos \theta_{ijk} - \cos \theta_0}^2}{1 + C_{ijk}\lr{\cos \theta_{ijk} - \cos \theta_0}^2}
\end{equation}  
where $B_{ijk}$ is the strength of the three-body term, $\xi$ and $C_{ijk}$ are constant parameters, and $\theta_{ijk}$ is the angle between $\vec{r}_{ij}$ and $\vec{r}_{ik}$.
The values of all these parameters depend on the system at hand. 
For instance, the strength of the steric repulsion, $H_{ij}$, for Si-Si interaction is different from that of Si-O interactions. 
For the case of silica, these metrics have been computed already, and when using the Vashishta potential in LAMMPS there is a file containing them.
As for the Lennard-Jones potential, the two-body potential term is truncated and shifted to prevent unphysical jerks, and retain stability. 
This is done the same way as in equation (\ref{eq:truncation}).





\section{Boundary conditions}
Boundary conditions is a crucial detail to decide upon when setting up a molecular dynamic experiment. The way we treat atoms at the boundary can have an immense effect on their behavior and how physically reasonable the results will be. There are several types of boundary conditions one may desire, and one may define custom conditions. A few examples are listed below. 
 

\hspace{-9.37mm}
\begin{tabular}{p{0.65\textwidth} p{0.3\textwidth}}
	\vspace{0pt}  {\it No boundary conditions}. Particles are not subject to any special rules at any boundry. The system size may be regarded as infinite. This  might be a reasonable choise when studying explosions for instance, or in experiments that is on a really short time scale.  
	& \vspace{0pt} \hspace*{-1.3cm} \includegraphics[width=1.3\linewidth]{figures/BoundaryConditions/no.pdf} 
	\\*
	\vspace{0pt} {\it Reflecting boundary conditions}, which act as hard walls. In stead of passing through the boundary, the velocity component in the direction normal to the face of the boundary changes sign, thus causing the atoms to be confined within the simulation box. 
	& \vspace{0pt} \hspace*{-1.3cm} \includegraphics[width=1.3\linewidth]{figures/BoundaryConditions/reflecting.pdf} 
	\\*
	 \vspace{0pt} {\it Periodic boundary conditions}, which allow atoms on separate sides of a boundary to interact through the boundary as if they were neighbors, and atoms crossing the boundary reappears on the other side of the simulation box. This is useful when studying bulk atoms of a material or materials that has a periodic structure.
	& \vspace{0pt} \hspace*{-1.3cm} \includegraphics[width=1.3\linewidth]{figures/BoundaryConditions/periodic.pdf}
\end{tabular}
\vspace{10mm}

\noindent
The boundary conditions may include more details than only how to handle the trajectory of atoms intersecting the boundaries. 
For instance with periodic boundaries, atoms that are far apart are effectively close. 
These atoms should therefore interact, since their motion would seem artificial otherwise. 
Thus, the interpretation of atoms positions must in some cases be included in the boundary conditions. 
In order to interpret atoms positions in the case of periodic boundaries, one has to remember that an atom should not interact with multiple images of another atom. 
Which image, if not the original, must therefore be decided. 
Also, an atom should not interact with an image of itself. That could potentially cause strange correlations. 
The standard way of determining atoms positions is by using the {\it minimum image convention}.


\subsection{Minimum image convention}
The minimum image convention simply states that the periodic image of an atom closest to the reference atom is the one to consider as its position. 
Example cases of 1D and 2D systems are shown in figure \ref{fig:minimumImageConvention1D} and figure \ref{fig:minimumImageConvention2D} respectfully. 
In the examples we look at systems consisting of two atoms and we try to determine the minimum image of the smaller, blue atom with respect to the larger, red, reference atom. 
The original system is distinguishable from the periodic copies by the background color; they have a slightly darker background. 
Also, we only bother showing the periodic copies of the atom of consideration, the blue one.  
The systems depicted are of size $L$ and $L\times L$ in the 1D and 2D cases respectfully.

By studying figure \ref{fig:minimumImageConvention1D} it becomes apparent that if the atom of consideration is closer to the reference atom than half the system length, the original image will be used to interpret its position. 
Otherwise, if it's farther apart than half the system length, a periodic image will be closer and therefor used as the atoms position.  
%Mathematically we can deduce that the position of the minimum image can be found as
%\begin{align}
%	\vec{r}_{ij}  = 
%	\begin{cases}
%	\vec{r}_{ij} - L, & \vec{r}_{ij} > L/2 \\
%	\vec{r}_{ij} + L, & \vec{r}_{ij} < -L/2
%	\end{cases}
%\end{align}  
This principle is applicable at higher dimensions as well. We simply decompose the positions and check each dimension separately. For a system of arbitrary number of dimensions the minimum image convention is assured by using the progression of lisiting \ref{mic}. 
Figure \ref{fig:minimumImageConvention2D} illustrate how we decompose the positional separation of the atoms in the 2D case.

\begin{lstlisting}[caption={Loop to compute the position of the closest periodic image of atom $j$ with respect to the referance atom $i$.}, label={mic}, language=c++]
for (int k=0; k<numberOfDimension; k++){
	delta[k] = atom[j].pos[k] - atom[i].pos[k]
	if (delta[k] > L/2) {
		delta[k] = delta[k] - L
	}
	else if (delta[k] < -L/2){
		delta[k] = delta[k] + L
	}
}
\end{lstlisting}

\begin{figure}[H]
	\centering{
		\def\svgwidth{\linewidth}
		\input{figures/minimumImageConvention/1D_2.pdf_tex}
		\caption{Minimum image convention in 1 dimension. 
		If an atom is separated from the reference atom (red) by more than half the system length, $L/2$, the minimum image convention states that the distance between the two is the distance to the periodic copy, which is $|\Delta x - L|$. 
		The white area indicates the system, while the gray areas are periodic replications of the system. Atoms in the gray areas are periodic images of the atom of consideration in the white area.}
		\label{fig:minimumImageConvention1D}
	}
\end{figure}

\begin{figure}[H]
	\centering{
		\input{figures/minimumImageConvention/2D_2.pdf_tex}
		\caption{Minimum image convention in 2 dimensions.
			The position of an atom, with respect to the reference atom (red), is the position of the original or any of the replicated images that has the shortest distance to the reference atom. 
			The minimum image is found by decomposing the atoms position, and carry out the 
			The shortest distance in this case is marked with an arrow. 
			Thus, when computing positional dependent quantities it's the position of the north-west replica that will be considered as the position of the blue atom in this case.}
		\label{fig:minimumImageConvention2D}
	}
\end{figure}

\section{Measuring physical quantities}
\subsection{Energy}
\subsection{Temperature}
\subsection{Pressure}
\subsection{Something else?}

\section{Thermostats}

From thermodynamics
we have that the kinetic energy, or total thermal energy is 
\begin{equation}
	E_k = \frac{f}{2} Nk_bT 
\end{equation}
, for a system of $N$ atoms with$f$ degrees of freedom and temperature $T$.  
$k_b$ is the Boltzmann constant. 
If we assume newtonian motion, the total kinetic energy in a system is statistically 
\begin{equation}
    E_k = \frac{1}{2}\langle m_i \vec{v_i}^2\rangle.
\end{equation}
We can equate these to find the statistical temperature given as
\begin{equation}\label{eq:MDtemperature}
	T = \frac{\langle m_i \vec{v_i}^2\rangle}{fNk_b}.
\end{equation}
Thus, we can approximate the instantaneous temperature using the atoms velocity.
This value will fluctuate about the real value, so time-averaging is often used when measuring.

Often, we want to control the temperature of our simulated system.
This is done by fixing the temperature in equation \eqref{eq:MDtemperature} and manipulate the atoms velocities.
There are several methods of manipulating the velocities, and these are called \textit{thermostats}. 
There are many different types of thermostats, and they all have their strengths and weaknesses.

We will look at two quite basic and different thermostats, as well as one that is common in professional use.   


\subsection{Berendsen}
The Berendsen thermostat rescales the velocity of all atoms in the system so that the temperature approaches that of the surrounding heat bath.
It rescales the atoms velocity by multiplying them by a scaling factor $\gamma$, given as 
\begin{equation}
\gamma = \sqrt{1+\frac{\Delta t}{\tau}\lr{\frac{T_{bath}}{T}-1}},
\end{equation}
where $\Delta t$ is the time step length, and $\tau$ is a relaxation time, which tune the coupling to the heat bath. 
$T_{bath}$ and $T$ is the temperature of the heat bath and the current temperature of the system, respectfully.
Typically the relaxation time is set to $\tau \approx 20\Delta t$. 
Using $\tau = \Delta t$ would result in the velocities rescaling so the temperature would be exactly the target temperature, $T_{bath}$, every time step. 
This thermostat suppress temperature fluctuations efficiently, rendering it well suitable for equilibration procedures.
However, because it rescales the velocities, it produce dynamics that are inconsistent with the canonical ensemble.



\subsection{Andersen}
The Andersen thermostat simulates the coupling between the system and an imaginary heat bath as collisions between their atoms. 
Atoms that collide are assigned a new normally distributed velocity with standard deviation  $\sqrt{3k_BT_{bath}/m}$ about the target temperature, $T_{bath}$.
The procedure of the thermostat goes as follows:
For each atom in the system, we generate a random uniformly distributed number in the interval $[0,1]$. 
If this number is less than $\Delta t/\tau$, the atom is considered to be colliding, and is assigned a new velocity. 
Here, $\tau$ is regarded as a collision time, and its value should be similar to $\tau$ in the Berendsen thermostat ($20\Delta t$). 
The Andersen thermostat is useful when equilibrating systems, but because randomly chosen particles are assigned randomly distributed velocities, it disturbs the dynamics of e.g. lattice vibrations. 
Also, this disturbance will decorrelate the system, rendering this thermostat ill-equipped when measuring e.g. diffusion coefficient.  
As a final note, if this thermostat is to be used, the newly assigned velocities may cause the systems center of mass to drift.


\subsection{Nosé-Hoover}



\section{Efficiency improvements}
The major part of the CPU time is spent in the force loop. 
At every time step we must recompute the force acting on each individual atom. 
When doing so, we should in theory include the contribution from all other atoms. 
Having a system consisting of $N$ atoms would result in $N(N-1)/2 \propto N^2$ computations, if we apply Newtons third law.
In this section we will look at the most fundamental efficiency improvements applied in molecular dynamics simulations.

\subsection{Cut-off}
Depending on the potential in use, the forces become negligible at certain distances. 
For instance if one uses the Lennard-Jones potential (introduced in section \ref{Lennard-Jones-section}) the contributions are practically zero for atoms positioned at a distance $r\geq2.5\sigma$.
Therefore, during a simulation we choose to only account for the contributions from atoms closer than this \textit{cut-off} distance, denoted $r_c$.  
%Atoms within the cut-off length from the atom of consideration are referred to as \textit{neighbor atoms}.
For the Lennard-Jones potentials the cut-off range is usually set to $2.5\theta$. 
Past this range, the pair-potential is practically zero. 
It's not zero, though. 
Without any alterations, particles intersecting the cut-off limit will experience an unphysical jerk, which may render the simulation unstable.  
To counteract this effect, we raise the potential, ensuring it and its derivative to be zero at the cut-off. 
We use the following adjustment.

\begin{equation}
	V(r) = 
	\begin{cases}
		\left.V(r) - V(r_c) - \frac{\partial V(r)}{\partial r}\right\rvert_{r=r_c} (r-r_c) &, r\leq r_c \\
		0 &, r>r_c 
	\end{cases}
	\label{eq:truncation}
\end{equation}
which implies the force
\begin{equation}
F(r) = 
\begin{cases}
F(r) = F(r) - F(r_c) &, r\leq r_c \\
0 &, r>r_c 
\end{cases}
\end{equation}
In practice we need to keep track of which atoms are within the cut-off range of each atom. 
This is achieved using cell lists and neighbor lists. 

\subsection{Cell lists and neighbor lists}
The main purpose of the cell list is to make the building of neighbor lists more efficient. 
We need to check which atoms are neighboring atoms, but obviously we do not need to check the entire domain, since the cut-off length is relatively small. 
Therefore, we partition the system into several cubes of size equal to the cut-off length. 
We store the atoms contained by each cell in a \textit{cell list}. 
Finally, when we build the neighbor lists we check only the atoms within the neighboring cells and those in the same cell, 27 cells in total. 
In this sense, by neighboring cells we mean any cells that share a face, edge or vertex. 
This is illustrated in figure \ref{fig:neighbourcells}.
The pay-off of using cell- and neighbor lists is tremendous. Since we now, for each atom, only include contributions from atoms within a constant volume of size $4\pi {r_c}^3/3$, 
the number of contributions will only depend on the density, which is an intensive\footnote{Physical property of a system that does not depend on the system size.} property. 
Thus, the number of computations is reduced to $\mathcal{O} (N)$, which is an immense relief in computational expense!

\begin{figure}
	\center
	\resizebox{0.45\linewidth}{!}{
		\input{figures/tikz/cubes.tikz}
	}
	\caption{Illustrative figure of cells of concern when building the neighbor lists. The lighter cubes are neighboring cells; the darker cube is the cell containing the reference atom. The 7 cells in front of the dark cell are removed from the figure, but are also included. }
	\label{fig:neighbourcells}
\end{figure}




\subsection{Parallelization}
It might be misguiding to refer to parallelization as an efficiency improvement, when on the contrary it most likely increases the CPU time usage. 
However, the real time consumed may be greatly decreased. 
It is intuitive that partitioning the work and processing these simultaneously will decrease the time as compared to processing it serially.   
The speedup is defined as 
\begin{equation}
S = \frac{T_s}{T_p},
\end{equation}
where $T_s$ is the time used when executing the program on a single processor, and $T_p$ the time used when running on $p$ processors simultaneously.
The time spent running a parallel implementation of a code using $p$ processors is seldom trivially $T_p=T_s/p$. This is due to the fact that there is a certain amount of time used on \textit{overhead}. This includes interprocess communications, idling and excess computations.
In molecular dynamics simulations there is communication between processors when building the cell- and neighbor lists, and when computing thermodynamical properties such as energy, pressure, temperature, etc.. 

During this project we have mainly been using the local supercomputer at the department of physics at the University of Oslo. It provides users with the possibility to run  up to 256 processes at once. Though, before doing so, it is considered as good practice to check the speedup obtained by using several numbers of cores.
In order to compute the speedup we initialized a system containing $15\times15\times15$ unit cells of beta-cristobalite and saved it as a restart file. 
We then remotely ran the input script shown in Listings \ref{lst:speedup} from the supercomputer using 1, 2, 4, 8, 16, 32 and 64 processors in the same fashion as shown in Listing \ref{speeduprun}.  
The resulting speedup of using the respective number of processors is plotted in figure \ref{fig:speedup15x15}.

\lstinputlisting[caption={LAMMPS input script executed using several numbers of processors, and timed separately.}, label={lst:speedup}]{../SiO2/small/continue.in}

\begin{lstlisting}[caption={Command used to excecute the input script speedup.in on 8 parallel processors and set the filename variable to speedup.restart.}, label={speeduprun}, language=c++]
mpirun -n 8 lmp_mpi -in speedup.in -var filename speedup.restart
\end{lstlisting}
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{figures/speedup/15x15.pdf}
	\caption{Speedup as a function of number of processors.}
	\label{fig:speedup15x15}
\end{figure}
The result indicate that the speedup is in fact not simply $S=p$. 
Anyhow, we clearly see the advantage of using 64 processors in parallel as opposed to 1. 
We can finish a job that would have taken an hour in two minutes!
Also, we clearly see that the initial claim holds; this is not more efficient when regarding CPU time. 
In fact this result suggest that using 1 processor is twice as energy efficient as using 64. 


\chapter{Friction}
\textit{The force that resists relative motion between two bodies in contact} \cite{frictionDefinition}. 
Friction is a well known phenomena, though still not fully understood.
Despite the fact that we learn about friction in introductory courses to physics, it is not at all easy to comprehend. 
It is very complex and still a field of research.
In this chapter we will look at fundamental concepts of friction, and distinguish macroscopic behavior from the microscopic.
 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.99\linewidth]{figures/friction/Colossus.jpg}
	\caption{Painting from the tomb of Tehuti-Hetep, showing the transportation of an Egytian colossus.}
	\label{fig:Colossus}
\end{figure}
\section{Historical note}
On the macroscopic level, friction has been observed since the dawn of man. 
Early actions that show awareness of the effects of friction was to chip stone in order to make tools, or rubbing wood in order to create fire. 
In the tomb of Tehuti-Hetep there was found the painting shown in figure \ref{fig:Colossus}, which show the moving of an Egyptian colossus. 
The statue is depicted pulled on a sledge, with officers standing on the front end of the sledge poring water on the ground. 
This is evidence that they perceived the effect of lubrication even then, 1900 B.C..   


\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\linewidth]{figures/friction/LeonardoDaVinciBW}
	\caption{Drawing from Leonardo da Vinci's notebook. From Codex Arundel, British Library, London (Arundel folio 41r).}
	\label{fig:leonardoDaVinci}
\end{figure}
\noindent 
The first documented studies of friction was carried out during the renaissance by Leonardo da Vinci (1452-1519) \cite{LeonardoDaVinciStudies}.
Among his experiments he attaching a block of wood to another object with a cord, and placed the block on a smooth surface.
He was able to adjust the weight of the second object, which he let hang over a fixed cylinder, free to rotate. 
This experiment was found in his notebooks, and is shown in figure \ref{fig:leonardoDaVinci}.
He experimented with tilted planes and placed the block on different sides, changing the apparent area of contact.
His results made him deduce the following statements, also found in his notes:
\begin{itemize}
	\item[] \textit{Friction produces double the amount of effort if the weight be doubled}. 
	\item[] \textit{Friction made by the same weight will be of equal resistance at the beginning of the movement though the contact may be of different breadths or lengths}.
\end{itemize}
This is now essentially known as the two first laws of friction. 
Leonardo also introduced the coefficient of friction 
\begin{equation}
	\mu = \frac{F}{L}, \label{eq:coefficientOfFriction}
\end{equation}
though he interpreted $L$ as the weight of the load and $F$ as the weight of the object pulling in a scenario as in figure \ref{fig:leonardoDaVinci}. The concept of \textit{force} was not commonly recognized until 200 years later. Isaac Newton's publication of \textit{Principia} paved the way for studies of friction, there among the most comprehensive study carried out by Charles Augustin Coulomb (1736-1806). He investigated the influence of several factors on friction, namely \cite{SlidingFriction}:
\begin{itemize}
	\item The nature of the materials in contact and their surface coatings.
	\item The extent of the surface area.
	\item The normal force.
	\item The amount of time that the surfaces remained in contact prior to the applied force.
	\item Ambient conditions.
\end{itemize}   
Among his results he found that the static friction force increased with the time the surfaces were in contact before applying shear force. 
Today this relation is known as
\begin{equation}
	F_s(t) = A+B\ln(t).
\end{equation}
Coulomb explained this behavior by regarding the materials as fibrous. 
Basically like a hairbrush, having fibers which get entangled into a mash when in contact. 
If the materials were in contact over a short period of time, fewer fibers would have gotten into their position in the mesh. 
When a shear force is applied, the fibers get tilted until they loosen from the mesh, at which point sliding occurs. 
This impression of the sliding mechanism is quite similar to the one we have now. 

Today we know that most surfaces are rough, at least at a microscopic level, having some degree of asperities. 
It is actually the asperities that are in contact with the other body. 
{\huge FIGURE MAYBE? } 
When there is contact between two surfaces, the asperities are pushed into the other material, and tries to occupy the position with the lowest potential.  
The asperities may move even though the macroscopic body is still. 
Thus, more time gives a higher rate of asperities that settle in positions with the lowest potential. 
 


\section{Macroscopic level}

\subsection{Coefficient of friction}
The coefficient of friction, $\mu$, is a dimensionless scalar describing the ratio between the force of friction and the normal force, as given in equation \eqref{eq:coefficientOfFriction}.
The value of $\mu$ is dependent on the material of the objects that are in contact. 
For most materials this coefficient is higher if the objects are stationary, than if they are moving relative to each other (sliding).
We may refer to them separately as the coefficient of static friction $\mu_s$, and the coefficient of kinetic friction $\mu_k$.
Thus, $\mu_s>\mu_ k$ for most materials\footnote{Teflon-on-teflon seems to have the same value for static- and kinetic friction.}.
If we attach a spring to a block and pull on the spring with a constant velocity, we may get the evolution of friction force as shown in figure \ref{fig:steadyslide}.
We assume the block to have a constant normal force from the surface it rests upon. 
The coefficient of static friction is found by using the maximum static friction force, $F_s$, in equation \eqref{eq:coefficientOfFriction}. 
Similarly the coefficient of sliding friction is found by using the value of the friction force in the sliding domain, $F_k$.
Keep in mind that the forces we refer to are considered to be working on the center of mass of the block. 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{figures/friction/steadySlide}
	\caption{Behavior of friction force as function of time, for a block pulled at constant velocity and under constant load, resulting in a steady sliding motion.}
	\label{fig:steadyslide}
\end{figure}


\subsection{Stick-slip motion}
If we pull on a body with a spring with constant and reasonably low velocity, it will be subject to a linearly increasing force (Hooke's law). 
Because the object does not slide until we reach the maximum static friction, it will remain its position until it does.
Once the force from the spring overcomes the maximum static friction, the body will begin to slide and the coefficient of friction changes to its kinetic state.
It will accelerate the most in the beginning, and continue increasing its velocity until it passes an equilibrium position.
Once it passes the equilibrium position, the friction force will overcome the spring force, and the velocity will decrease. 
When the velocity is sufficiently low, the object will stop abruptly. 
As the spring is still being moved, the spring force on the object will rise again, and we have a complete cycle.
The time evolution of the force applied by the spring will be similar to the sketch shown in figure \ref{fig:stick-slip}.
If the surface of the block or substrate is non-homogeneous, the stick-slip motion may be more chaotic, than illustrated by the sketch. In fact, it may be difficult to find any periodicity in the motion at all. We are not going to concern our self with chaotic stick-slip motion, since we will have perfectly smooth, dry and pure surfaces when doing molecular dynamics simulation.  


\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{figures/friction/stick-slip}
	\caption{Behavior of friction force as function of time, for a block pulled at constant velocity and under constant load, resulting in a stick-slip motion.}
	\label{fig:stick-slip}
\end{figure}

Whether the motion is of the steady type or the stick-slip type, is found experimentally to be depending on the velocity and  stiffness of the spring.
At sufficiently high speeds, we would always get a steady motion. 
Similarly, with a stiff enough spring we would also get a steady motion. 
While with a velocity, $v<v_s$, and stiffness $k<k_s$ we would expect a stick-slip motion.
This can be illustrated by a phase diagram of velocity and spring stiffness $(v,k)$, as in figure \ref{fig:phase-stick-slip}.
The change in behavior can be observed in our daily lives. 
The creeking of a door is due to stick-slip motion at the hinges.
However, if we open the door quickly, the door will not creek.  
%The sound produced by bowed instruments such as the cello or violin are dependent of the speed at which the bow is drawn across the strings. 
 
  

\begin{figure}[H]
	\centering{
		\def\svgwidth{0.5\linewidth}
		\input{figures/friction/phase.pdf_tex}
		\caption{Phase diagram of velocity and spring stiffness ($v,k$). 
			All combinations within the gray area will result in a stick-slip motion. 
			All outside will result in a steady sliding motion.}
		\label{fig:phase-stick-slip}
	}
\end{figure}







%In order to understand the behavior on the macroscopic level, we study the dynamics at a microscopic level as well. 
%As it turns out, there are several similarities and differences between these length scales.





















\chapter{LAMMPS}

LAMMPS is an acronym for \textit{Large-scale Atomic/Molecular Massively Parallel Simulator}. 
It is a classical molecular dynamics simulation code designed to run efficiently on parallel computers. 
It's development began in the mid 1990s at Sandia National Laboratories, with funding from the U.S. Department of Energy. 
It was a cooperative project between two DOE labs and three private companies. 
The development is still ongoing and contributions are revised thoroughly. 
Today LAMMPS is an open-source code with extensive and user friendly documentation. 
This is one of the main reasons why we have chosen to use LAMMPS as opposed to other molecular dynamics software. 

In this chapter we will be presented with a guide to install LAMMPS, a brief explanation of commands and syntax, and an example of a valid input script.
\section{Installation}
Installing LAMMPS is a fairly simple procedure if only the basic settings are needed.

\subsection{Linux}
Users with a Unix based OS may download the lammps distribution as a tarball from LAMMPS' download page\footnote{\href{http://lammps.sandia.gov/download.html}{http://lammps.sandia.gov/download.html}} and then unpack it from the command line.
\begin{lstlisting}
gunzip filename.tar.gz
tar xzvf filename.tar
\end{lstlisting}
The user should then change directory into \texttt{/path/to/lammps/src/}, and execute the following commands in order to list available packages. 
\begin{lstlisting}
make package-status
\end{lstlisting}
Installing specific packages is accomplished as shown below.
\begin{lstlisting}
make yes-molecule yes-manybody yes-python yes-rigid 
\end{lstlisting}
The above example installs the packages \textit{molecule, manybody, python and rigid}.
Next, the user can build LAMMPS using either of the lines below. 
Assuming the user has MPI installed, line 2 makes the resulting executable compatible with parallelization in MPI.
\begin{lstlisting}
make serial
make mpi
\end{lstlisting}
At this point there should be an executable in the \texttt{/path/to/lammps/src/} directory named \texttt{lmp\_serial} or \texttt{lmp\_mpi}, depending on the previous choice. These are now ready to run.
To use it one has to point to this file from the command line at every run. It may be practical to set up a symlink as shown below.
\begin{lstlisting}
sudo ln -s /path/to/lammps/src/lmp_mpi /usr/local/bin/lmp_mpi
\end{lstlisting}
Then the executable will be available as \texttt{lmp\_serial} or \texttt{lmp\_mpi} from any directory. 

\subsection{Mac OS X with Homebrew}
Mac users can follow the procedure described above, however they may also install even easier using \textit{Homebrew}\footnote{\href{http://brew.sh/}{http://brew.sh/}}. 
\begin{lstlisting}
brew tap homebrew/science
brew install lammps              # serial version
brew install lammps --with-mpi   # mpi support 
\end{lstlisting}
Where the user obviously should choose either line 2 or line 3, depending on whether the user wants MPI comparability.
This will install an executable named "lammps", a python module named "lammps", and resources with standard packages. 
This is basically it. LAMMPS is now ready to run, however, not all packages are installed.
The location of the resources and available packages can be found using the following command.
\begin{lstlisting}
brew info lammps 
\end{lstlisting}
Specific packages are available as options, and may be installed using the following syntax.

\begin{lstlisting}
brew install lammps --enable-manybody 
\end{lstlisting}
In the example shown we installed the package manybody.


%\subsection{Windows}



\section{Input scripts}
The executable made in the previous section can be used to read so-called input scripts. 
The input scripts contain LAMMPS commands to configure the simulation. This includes all settings and actions. 
This is naturally partitioned into two sections: \textit{system configurations} and \textit{run-time commands}.
The scripts are executed on 8 CPU's in parallel as
\begin{lstlisting}[language=c++]
mpirun -n 8 lmp_mpi -in in.system
\end{lstlisting} 
Despite the widely common convention of letting the file type be determined by the letters following the punctuation mark, it's common in the LAMMPS manuals to name the input scripts with the name last. i.e. \texttt{in.name}. Luckily, both conventions are meretricious since the executable accepts any name/type for the input script.
\subsection{System configurations} \label{sec:systemConfigurations}
The first part of every input script contains information of the system properties. This includes: size, number of dimensions, boundary conditions, potentials, unit convention, information on the containing atoms, time step length, neighbor list update frequency and possibly a lot more.   
Listing \ref{lammpsInput1} show the configurations that has been used for the entire duration of this project. 
Below there is a description of each command and its purpose.


\begin{lstlisting}[language=LammpsInput, caption={Typical system configurations applied in this project.}, label={lammpsInput1}]
units        metal
boundary     p p p
atom_style   atomic
read_data    "system.data"
pair_style   vashishta
neighbor	   0.3 bin
neigh_modify delay 10
timestep	   0.002
\end{lstlisting} 
%pair_coeff   * *  SiO2.vashishta Si O
%pair_modify  table 16
%pair_modify  tabinner 0.1

\paragraph{\texttt{units}} determines what unit convention should be used for the simulation. It might not seem like a difficult decision, but if you import data from a file for instance, it is crucial that LAMMPS interpret the data correctly. In this project we have chosen \textit{metal} as the unit convention. The units are therefore as shown in table \ref{tab:unitsMetal}.

\paragraph{\texttt{boundary}}  sets the style of boundaries for the simulation box in each dimension. There are four options: \texttt{p}, \texttt{f}, \texttt{s} and \texttt{m}. In the example above, we have chosen to use periodic boundaries through all the faces of the simulation box. It's possible to set different conditions in separate dimensions, e.g. \texttt{boundary   p f p} sets fixed boundaries on the faces normal to the y-direction.  One can even set different conditions on the two faces in the same dimension by using two letters, e.g.   \texttt{boundary   p fs p}, where the first letter indicates the boundary to be used on the \textit{low face} and the last on the \textit{high face}. 

\paragraph{\texttt{atom\_style}} tells LAMMPS the structure of atom related data stored in a data file. This includes information about particle types, positions, charges, mass,  bonds, angles, and potentially more, depending on the \texttt{atom\_style}. 

\paragraph{\texttt{read\_data}} reads a data file containing information as described above and additional information about the system, such as its size and shape. 
This is one of three ways to distribute initial atom positions. 
Another is the \texttt{read\_restart} command, which is used extensively to load saved states from restart files. 
The last option is to use \texttt{create atoms}, which distributes atoms in a predefined way, i.e. in a lattice or a random collection. 
To use this last option, one has to first create a simulation box using the \texttt{create box} command.  

\paragraph{\texttt{pair\_style}} determines which potential to use in the simulation.

%\paragraph{\texttt{pair\_coeff}}

\paragraph{\texttt{neighbor}} sets the additional range of the neighbor list cutoff, and the method of constructing the neighbor lists. 
The consequence of having a larger range for the neighbor lists is that there are more particles to check for force contribution, however, we don't have to update the neighbor lists as often.  

\paragraph{\texttt{neigh\_modify}} determines how often to update the neighbor lists. 

\paragraph{\texttt{timestep}} self-explanatory.








\subsection{Run-time commands} 
\subsubsection{Variables}
LAMMPS offer the ability to store values in variables. These can be constants or dependent on other variables, like the time step for instance. Declaration of variables is done using the following syntax.
\begin{lstlisting}[language=LammpsInput, caption={Declaration of variables.}, label={lammpsVariable}]
variable A equal 1000
variable B equal step/${A}
variable C equal ${B}
variable D equal v_B
\end{lstlisting} 
All of the above are valid variables. 
The \texttt{step} variable is a LAMMPS standard for current time step.
We attend for \texttt{B} to be a linear function running from 0 to 1 over the course of \texttt{A} time steps. 
\texttt{C} evaluates \texttt{B} at the time step it is declared and returns that value whenever called upon. 
Thus, \texttt{C} will be a constant value.
\texttt{D} will evaluate \texttt{B} whenever called upon, and return the current value of variable \texttt{B}. 
The variables \texttt{C} and \texttt{D} are of course superfluous, since we could only use \texttt{B} directly.
The user can use math operations on variables, such as: addition, subtraction, multiplication, division, as well as square roots, logarithms, exponentials, and lots more.


\subsubsection{Region \& Group}
In almost all simulations it is necessary to define regions and groups in order to give certain parts of the domain special properties. 
If the user wish to create a sphere of atoms, the typical process is to start from a block of atoms, define a spherical region in the block and remove exterior atoms. 
The regions specified can take the shapes: block, cone, cylinder, plane, prism or sphere, and regions can be combined.
An example of removing atoms within a combined region is shown in listing \ref{lst:sculpting}. 
This example also show how to assign a group to atoms within a region. 
Each atom can be part of up to 32 different groups at a time. 
The user can do tons of actions on groups. 
Most computes and fixes act on specific groups. 
There is only one standard group in LAMMPS; the group \texttt{all}.

\subsubsection{Computes}
A compute defines a computation that will be performed on a group of atoms. 
This does not affect the dynamics in any way.
The returned values are instantaneous. 
That is, they are computed from information about atoms on the current time step. 
The returned  values can be global, local or per-atom quantities.
These can be retrieved by an output commands using the following syntax:
\begin{lstlisting}[language=LammpsInput]
c_computeID
c_computeID[1]
c_computeID[*][2]
\end{lstlisting} 
The first alternative would return all values (scalars, vectors, arrays) computed. 
The second would return only the first element of a vector, or row of an array, 
and the last one would return the second element of all rows of an array. 
Note that LAMMPS counts from 1, which also deviate from other established standards.
In section \ref{section:LAMMPSOutput} we will see this in several example, where we refer to the \texttt{compute com} command. 
\begin{lstlisting}[language=LammpsInput]
compute comID groupID com
\end{lstlisting} 
This computes the position of the center of mass of all atoms within the specified group, and stores the result in a 3-element vector.
 





\subsubsection{Fix}
A fix is an operation that's applied to the system during time iteration. 
Examples include time evolution of atoms, i.e. updating their positions and velocities, using thermostats, applying external force on atoms, averaging values, etc. 
There are numerous fixes and computes in LAMMPS, and you can easily add new ones if you knows the structure of the framework.
Some Fixes also compute and store values that can be retrieved by output commands. 
For instance the \texttt{fix addforce} command
\begin{lstlisting}[language=LammpsInput]
fix addforceID groupID addforce fx fy fz
\end{lstlisting} 
adds a given force to all atoms within the specified group. 
This \texttt{fix} stores the total force acting on the group before the force was added. 
This is stored as a 3-element vector.
Its values can be obtained in the same manner as for computes:
\begin{lstlisting}[language=LammpsInput]
f_fixID
f_fixID[1]
f_fixID[*][2]
\end{lstlisting} 



% In LAMMPS, a “fix” is any operation that is applied to the system during timestepping or minimization. Examples include updating of atom positions and velocities due to time integration, controlling temperature, applying constraint forces to atoms, enforcing boundary conditions, computing diagnostics, etc. There are dozens of fixes defined in LAMMPS and new ones can be added; see this section for a discussion.
\subsection{Output} \label{section:LAMMPSOutput}
In order to benefit from our simulations, we need to be able to extract the data of interest somehow. 
Here we will present the four most basic types of output.




\subsubsection{Thermodynamic output} 
prints computed values to the screen and logfile every $N$ time steps. It is activated by the command 
\begin{lstlisting}[language=LammpsInput]
thermo N
\end{lstlisting} 
where N should be replaced by the desired frequency of the output. This can be a variable.
The default quantities given in the output are: time step,  temperature,  pairwise energy, molecular energy,  total energy and pressure.
The user can specify what values should be included by using the \texttt{thermo\_style} command with the syntax of the following example.
\begin{lstlisting}[language=LammpsInput]
thermo_style custom step c_comID v_Fz f_addforceID[3]
\end{lstlisting} 
This line specifies that when the thermodynamic output is printed, it should contain the time step, all quantities returned by the compute \texttt{comID}, the current value of the variable \texttt{Fz} and the third element of the vector retrieved by the fix \texttt{addforceID}. The naming of the compute- and fix names can be whatever desired, even numbers.
I just find it convenient to name them by what they represent. 

\subsubsection{Dump} 
Dump files  store data about the state of atoms in a specified group with the given frequency. 
Below we illustrate two quite different dump commands.
\begin{lstlisting}[language=LammpsInput]
dump dumpID1 all atom 100 name.dump
dump dumpID2 groupID custom 50 name*.dump id x y vx fx
\end{lstlisting} 
Line 1 creates a file named \texttt{name.dump}. Every 100 time steps it writes data to this file in the \textit{atom} format, i.e. \texttt{id type xs ys zs}, where \texttt{xs}, \texttt{ys} and \texttt{zs} are scaled coordinates relative to the size of the simulation box. 
Line 2 creates a file for every time step, where the asterisk in the name is replaced by the current time step. Also we define the format of the output to be unscaled x- and y-coordinates, as well as velocity and force in the x-direction. 
 
Common visualization software can read most of the predefined formats in LAMMPS: atom, xyz, cfg, etc..


%, which contain snapshots of atoms and various per-atom values and are written at a specified frequency.
\subsubsection{Fix} 
Certain fixes can also write specified quantities to files. For instance the commands 
\begin{lstlisting}[language=LammpsInput]
fix timeAvgID all ave/time 100 5 1000 c_comID file name.avg
fix spatialAvgID all ave/chunk 100 10 1000 chunkID c_comID file vel.profile
\end{lstlisting} 
do respectfully time- and spatial averaging of the values returned by the compute \texttt{comID}. The numbers indicate how many values should be sampled, number of time steps between each sample, and how often to write this average to file. Note that the last command refers to a \texttt{compute chunk}, which governs how to grid the system. 
There is also a \texttt{fix print} command that writes single-line output to screen or file with a prescribed frequency.
\begin{lstlisting}[language=LammpsInput]
fix printID all print 100 "z-component of COM: c_comID[3]" 
\end{lstlisting} 
This acts practically like the \texttt{thermo} command.


\subsubsection{Restart files}
In many cases it is practical to save certain checkpoints in a simulation, in order to be able to start a new simulation from said point. 
The \texttt{restart} command does just that. 
\begin{lstlisting}[language=LammpsInput]
restart N name.*.restart
\end{lstlisting} 
This command saves the state of the system every \texttt{N} time step to individual restart files, distinguishable by the number representing the time step of the save. 
By "state of the system" we mean positions and velocities of all atoms, information of what groups each atom belongs to, the size and shape of the simulation box, boundary conditions, potential,  etc.. 
When starting a new simulation, one of these "snapshots" can be loaded using the \texttt{read\_restart} command as illustrated below.
\begin{lstlisting}[language=LammpsInput]
read_restart name.timeStep.restart
\end{lstlisting} 



\section{Visualization}
The LAMMPS package does not provide high-quality visualization software. However, the default formats of the dump command are well known to most of the ones out there. 
A couple of so-called high-quality visualization tools are listed below:
\begin{itemize}
	\item VMD
	\item AtomEye
	\item OVITO
	\item ParaView
	\item PyMol 
\end{itemize}
In this section we will discuss hos to visualize an MD simulation and some of the features of one of the softwares listed, namely Ovito. Lastly we will be presented with a new concept that is currently under development here at the University of Oslo; a software named Atomify.

\subsection{OVITO}

\chapter{Preparing a molecular dynamics simulation}

We wish to construct a system consisting of {\color{red} two} elements made out of silica: a slab and a sphere cap. In order to do this we need to generate the spacial position coordinates (x,y,z) of every single atom. Considering that we are making a system consisting of about $10^5$ atoms, this is obviously not done manually. We have chosen to use a tool named \textit{Moltemplate}\footnote{\href{http://www.moltemplate.org/index.html}{http://www.moltemplate.org/index.html}}, which is included in the LAMMPS distribution.

The main idea is to manually enter the coordinates of only the atoms in a unit cell of the material one wish to generate, and then simply copy this unit cell wherever desired. The software will shift the coordinates of the copied unit cell by the displacement from the original image. In addition it will generate files containing data such as which atoms they share bonds with, if any, and angles between such bonds. 

\section{Silica}
Silica is a chemical compound also known as Silicon dioxide, having the chemical formula SiO$_2$. It has several polymorph structures, the most common being quartz, which is one of the most abundant minerals in the Earth's crust. Other polymorphs include cristobalite, tridymite, coesite and more.    
For our purpose it is insignificant which one we choose. 
Once the material is melted, it is indifferent which configuration we started from, as long as the density is correct.
In this project we will build the constituents of the system from a type of cristobalite named $\beta$-cristobalite. This is mainly because it has a simple structure and a cubical unit cell.


\subsection{Unit cell of $\beta$-cristobalite}
In order to construct the unit cell of a material, one should look up the coordinates of the atoms in a crystallography database. We have used the unit cell of $\beta$-cristobalite found at \textit{Crystallography Open Database}\footnote{\href{http://www.crystallography.net/cod/1010944.html}{http://www.crystallography.net/cod/1010944.html}}. 
At this site one can download a \texttt{.cif}-file (Crystallographic Information Framework) containing information about the spatial positions of each atom, the length of the unit cell edges and angles between faces of the cell. 
In the case of $\beta$-cristobalite the unit cell is cubical with edges of length 7.12Å. 
It contain 8 silicon atoms and 16 oxygen atoms. 
The density of the unit cell can easily be computed and is 2.2114 g/cm$^3$.
The format of th \texttt{.cif}-file is not easily readable. To extract the information we have used a tool named \texttt{cif2file}\footnote{\href{http://www.cif2cell.com-about.com/}{http://www.cif2cell.com-about.com/}}, developed by Torbjörn Björkman. 

\begin{figure}
	\centering
	\includegraphics[width=0.6\linewidth]{figures/unitcell/unitcell.png}
	\caption{Unit cell of b-cristobalite. Tan and blue spheres represent silicon and oxygen atoms respectively. The unit cell is cubical, with edges of length 7.12Å.}
	\label{fig:unitcellbcristobalite}
\end{figure}



\section{Building a crystal}
The coordinates gotten from the \texttt{.cif}-file can now be implemented into \textit{moltemplate} together with whatever bond and angle data required by the potential. In our simulations we will use the Vashishta potential, which does not require these. 
Moltemplate has its own structure and syntax. 
The first step to build up a larger material is, as mentioned, to create the unit cell. 
Data concerning the unit cell are placed in a \texttt{.lt}-file, which is readable by Moltemplate. 
Such a file is shown in Listing \ref{lst:beta-cristobalite.lt}. 
For a more profound understanding of the structure and syntax of these files, the reader is advised to read the moltemplate manual\footnote{\url{http://www.moltemplate.org/doc/moltemplate_manual.pdf}}.


\lstinputlisting[caption={Typical Moltemplate file containing unit cell data. The columns of the "Data Atoms" section hold, from left to right, information of atom ID, atom type, x-, y- and z-position. The "Data Masses" section stores the weight of silicon and oxygen atoms in atomic mass units.}, label=lst:beta-cristobalite.lt, language=LammpsData]{../SiO2/large/beta-cristobalite.lt}


We use the unit cell as building blocks, placing them concurrently until we have a crystal of the desired size. For example purposes, we generate a large cube of $15\times15\times15$ unit cells. This is done in line 17-21 of listing \ref{lst:cubeSiO2} below.
%\lstinputlisting[caption={Moltemplate script to build a cube out of $15^3$ unitcells of $\beta$-cristobalite, and also specify system configurations (see section \ref{sec:systemConfigurations}). The "write\_once" sections create the files containing their contents. Line 17 imports the unit cell shown in listing \ref{lst:beta-cristobalite.lt}, and line 19-21 copies it concurrently in a $15\times15\times15$ cube.}, label=lst:cubeSiO2, language=LammpsData]{../SiO2/large/system.lt.latex}
{\Huge Uncomment the above listing!}
The \textit{write\_once} sections with "In" as the first word of its argument, creates the files \texttt{system.in.init} and \texttt{system.in.settings}, which contain exactly what is shown in the snippet. 
They are not necessary, but help making the LAMMPS input script cleaner, since we can \texttt{import} these files instead of having all the configurations in the input script file.
The last \textit{write\_once} section with "Data" in its argument, incorporates the specified size of the simulation box in the \texttt{system.data} file. 
Line 19 creates a new unit cell at every point separated by 7.12\AA ~in all three dimensions. The positions, and other properties defined by the \textit{atomstyle}, of all the distributed atoms are stored in the file \texttt{system.data} as well. 

The Moltemplate script can be run from the command line as
 \begin{lstlisting}
 moltemplate -atomstyle "atomic" system.lt
 \end{lstlisting}
Once complete, we can load the configurations and atomic data into our LAMMPS input script simply by including the file \texttt{system.in}.



\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{figures/CreatingSystem/hugeCube}
	\caption{System built from $15\times15\times15$ unit cells of b-cristobalite.}
	\label{fig:hugeCube}
\end{figure}


\section{Verifications}
\subsection{Melting point}
Finding the melting point is a very important verification of our system. 
There are several factors that may affect the result. For instance, if the density of the system is too high, the melting point will be at a higher temperature than it normally would. 
Also, errors in the potential model may affect the temperature of the melting point. 
When increasing the temperature of the system that is in a solid state, we will eventually reach the melting point.
At the phase transition from a solid state to a liquid the atoms of the silica will have energy great enough to break the interatomic bonds. 
They will break loose from their regular arrangement and move about much more freely. 
An approach to computing the melting point is therefore to systematically increase the temperature stepwise and sample the mean square displacement of the atoms at each designated temperature.  
The mean square displacement is the average of the square of the displacement every atom has from its initial position. It can be expressed as:
\begin{equation}
\langle r^2(t)\rangle = \frac{1}{N}\sum_{i=1}^{N}\lr{\vec{r}_i(t)-\vec{r}_i(0)}^2. \label{eq: diffusion constant}
\end{equation}
where $\vec{r}_i(t)$ is the position of atom $i$ at time $t$ and $N$ is the total number of atoms. 
In practice the mean square displacement was computed using a standard \textit{compute} in LAMMPS, namely the \textit{msd compute}\footnote{\url{http://lammps.sandia.gov/doc/compute_msd.html}}. 
At every time step it stores a vector of 4 elements; the first 3 are the squared $dx$, $dy$ and $dz$ displacements averaged over the atoms of the specific group, while the 4th is the total mean square displacement for the specific group, i.e. $(dx^2 + dy^2 + dz^2)$. 
The $15\times15\times15$ system is sufficient for this test. The procedure is rather simple. For $\beta$-cristobalite we expect the melting point to be about 1986K\footnote{\url{https://en.wikipedia.org/wiki/Cristobalite}}, so we start out at 1500K. After equilibration the following steps are repeated until we reach a target temperature. 
\begin{itemize}
	\item equilibrate for the current temperature
	\item compute the msd for $N$ time steps
	\item increase the temperature by a given step size
\end{itemize}
\lstinputlisting[caption={Section of LAMMPS script illustration how to stepwise increase temperature and compute the mean square displacement of atoms.}, label={lst:msd}, firstline=14, lastline=40]{../SiO2/msd/continue.in}
\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{../SiO2/msd/figures/msd}
\caption{Mean square displacement as a function of temperature. The face transition occurs where we see a rapid change in the behavior.}
\label{fig:msd}
\end{figure}
This result infer a melting point somewhere in the range 1800K-1900K. 
Believe it or not, this is actually a pass on the test! 
In fact, anything deviating less than $20\%$ from the experimental results is considered a pass, as stated by the developers of the potential. 
Unfortunately, this also show that there are some qualitative detail that is lost, and that when using this potential we should probably focus on the quantitative behavior. 





\section{Shaping the silica}

%\begin{figure}
%	\centering
%	\includegraphics[width=0.7\linewidth]{figures/CreatingSystem/drawing.pdf}
%	\caption{Illustrative drawing of what how the system should look. Red parallel stripes symbolize areas of silica. Red crossing stripes indicate areas of frozen silica. The boundaries are periodic in all dimensions, causing both the slab and the sphere to be connected to the frozen silica through the z-boundaries.}
%	\label{fig:drawing}
%\end{figure}

The huge cube of silica can be carved however we like by defining regions from which we delete the containing atoms. 
In LAMMPS this is done using the \texttt{region}, \texttt{union}, \texttt{intersect} and \texttt{delete\_atoms} commands. 
Our implementation is stated in Listing \ref{lst:sculpting}, which is very simple due to the way we are going to treat the boundary conditions. 
We start out by defining a spherical region labeled \texttt{sphereRegion}, described by the xyz-coordinates of its center and a radii. 
The atoms within this region are assigned to a group labeled \texttt{sphereGroup}. 
Next, we define a cuboid (block) region named \texttt{slabRegion}, described by the position of its faces in x-, y- and z-direction. 
The atoms within this region are assigned to a group, which we label \texttt{slabGroup}.  
We combine these two regions using  the \texttt{union} command and label the region outside of these regions \texttt{outRegion}.
Finally, we delete the atoms that are not in the sphere nor the slab; we delete the ones contained by \texttt{outRegion}.
\lstinputlisting[caption={Defining regions to keep or delete from a system of dimensions $106.8\times106.8\times106.8$ Å.}, label={lst:sculpting}]{../SiO2/small/system.prepare.latex}
For the purpose of deleting atoms, the creation of groups was superfluous. %redundant
However, at a later stage we will utilize them and this is an appropriate place for them to be assigned. 
The appliance of the script in Listing \ref{lst:sculpting} on the system is shown in figure \ref{fig:hugeCube} is shown in figure \ref{fig:carvedxz}, where our perspective is along the y-axis.

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{figures/CreatingSystem/carved_xz.png}
\caption{xz-perspective on a system built from $15\times15\times15$ unit cells of b-cristobalite, with certain regions carves out. This is a result from applying Listing \ref{lst:sculpting} to the system shown in figure \ref{fig:hugeCube}. The top shape is a sphere cap, while the bottom is a slab.}
\label{fig:carvedxz}
\end{figure}


\section{Moving the sphere towards the slab}
We wish to push the sphere down onto the slab in order to create a deformation on the slab. There are probably a lot of smart ways to do this. The author has settled on the following strategy:

We apply periodic boundary conditions in all three dimensions. 
%This will in practice imply that the sphere cap and the slab are connected through the z-boundaries. 
Secondly, we freeze the atoms at the bottom of the slab so that their positions are fixed. 
This will, due to the periodic boundary conditions, allow us to consider the sphere cap and the slab as if they are not connected to each other, but to independent blocks of silica glass.  
Then, for every $N$ time steps we decrease the hight of the system, while remapping the positions of the atoms. 
The remapping is a very important procedure. 
It ensures that we do not loose any atoms that elsewise would be lost when moving the z-boundary. 
A side-effect of the remapping is that the atoms in the system will be somewhat compressed in the z-direction. 
Though, if we do the compression slowly, this will not be of any concern. 

\begin{lstlisting}[caption={LAMMPS commands for hard coding the forces and velocities of atoms within a specific group. Effectively freezing them.}, label={FreezeStuff}, language=c++]
fix freezeID groupID setforce 0 0 0
velocity groupID set 0 0 0
\end{lstlisting}

\begin{lstlisting}[caption={LAMMPS command for changing the size of the simulation box.}, label={Deform}, language=c++]
fix ID all deform 1 z delta 0 -${compressionLength} remap x
\end{lstlisting}
 



\chapter{This must be sorted in designated chapters}

\section{Radial distribution of normal force}
In order to find a radial distribution of the normal force, $F_N$, we partition the system into a grid in  the xy-plane. We then use the command 

\begin{lstlisting}[language=LammpsInput]
	compute chunkID all chunk/atom bin/2d x 0 7.12 y 0 7.12
	compute stressID all stress/atom NULL
	fix fixChunkID all ave/chunk 1 1 10 chunkID c_stressID[3] file forcesInChunks.txt
\end{lstlisting} 
to compute the stress of every chunk in the z-direction, $\sigma_{zz}$ (sum of every individual atom stress in the chunk). 

Line 1 establishes the grid, with bin width $7.12$Å.

Line 2 creates a compute of the stress

Line 3 stores the sum of individual stresses in each chunk to the file \texttt{forcesInChunks.txt}. 
This is done every 10 time steps in order to reduce correlation effects. 

The data in stored from each time step can easily be averaged to produce a result as shown in figure X.

We can then find the radial distribution simply by binning this matrix in radial bins, and average the normal forces of the chunks within the bins.

\subsection{Radial binning}
Our system is partitioned into a grid. 
Each cell in the grid holds an averaged value of the normal force in that cell. 
The radial distribution of normal force should express the averaged value of the normal force at a given radial distance from the {\color{editColor}center of the sphere}. 
A coarse method of doing this is to average the weights of the cells who's center is within the bin. 
This is illustrated in figure \ref{fig:radialBinningChoars}. 
In many applications where the bin size can be large compared to the length of the cells, this method might suffice.
However, the current radii of the contact area between the sphere and the slab is only about 10 unit cells, and therefor having a large bin width will result in very few data points. 

 \begin{figure}
 	\center
 	\resizebox{0.48\linewidth}{!}{
 		\input{figures/tikz/radialBinning.tikz}
 	}
 	\caption{Coarse radial binning. The value appointed to the radial bin is the average of the weights of the cells who's center is within the bin. The cells with center within the third radial bin are colored, and their centers drawn.}
 	\label{fig:radialBinningChoars}
 \end{figure}

A different, slightly more sophisticated approach is to compute the fraction of the area of each cell that actually is withing the bin, and multiply this by the weight associated with the cell.
We can sum all these contributions and average them by dividing by the area of the bin. 
This means that even cells that do not have their center within the bin might contribute to the resulting bin value. 
How much, however, will depend on the fraction of the cell that is within the bin.
This may be regarded as a smoothing of our coarse force distribution, and will probably give a more correct result than the coarse binning method already described. An illustration of this binning method is shown in figure \ref{fig:radialBinningSmooth}.
The figure clearly show that some cells have a larger area within the bin than others, and thus contribute more. 

{\color{editColor}{\Huge Computing the area of the cell within the bin should be described here!}}


 
 
 

\begin{figure}
%\begin{minipage}[t]{0.49\linewidth}
%	\captionsetup{width=\textwidth}
    \centering
	\resizebox{0.5\linewidth}{!}{
		\input{figures/tikz/radialSmoothing.tikz}
	}
	\caption{Radial binning based on weighted contributions of intersecting cells. The third radial bin is colored, and its value will be the average of the intersecting cells weight times the fraction of the cells area that intersects the bin.}% A close-up of the outlined cell, is shown in figure \ref{fig:radialBinningSmoothCloseUp}.}
	\label{fig:radialBinningSmooth}
%\end{minipage}
%\quad
%\begin{minipage}[t]{0.49\linewidth}
%	\captionsetup{width=\textwidth}
%	\resizebox{\linewidth}{!}{
%		\input{figures/tikz/radialSmoothingCloseUp.tikz}
%	}
%	\caption{Close-up of outlined cell in figure \ref{fig:radialBinningSmooth}. The contribution from this cell will be it weight multiplied by the fraction of its total area that is colored. I might use this figure to explain the procedure. }
%	\label{fig:radialBinningSmoothCloseUp}
%\end{minipage}
\end{figure}

\begin{figure}
	\centering
	\hspace{0.87cm}
	\includegraphics[height=0.482\linewidth]{figures/forceDistribution/radialDistribution/weights.pdf}
	\caption{Fraction of cell's area that are within the third radial bin. }
	\label{fig:radialBinningWeights}
\end{figure}



\begin{figure}
	\center
	\resizebox{0.5\linewidth}{!}{
		\input{figures/tikz/stressTensor/stressTensor.tikz}
	}
	\caption{Stress}
	\label{fig:stressTensor}
\end{figure}


\chapter{Computing the normal force distribution}
The normal force is defined as the force exerted on an object that is perpendicular to the contact surface. 
%The system we have created will have a non-zero normal force in the indentation of the substrate. 
In this chapter we will make an attempt to find the distribution of the normal forces. 
This is not a trivial thing to compute in LAMMPS. 
As a matter of fact, to achieve this we have expanded the LAMMPS library by creating a custom compute class. 
The details of that procedure will be described. 

Our strategy is simple, but not necessarily easy. 
First of, we divide the system into a grid. 
Secondly,  we compute the average force exerted on one body from another within each cell. 
We approximate the slope of the contact surface within the cells using a least squares regression method. 
Finally, we project the average force of the atoms in a cell onto the normal vector of the cell.


\section{Creating a custom compute}
A \textit{compute} is a LAMMPS command that defines a computation that will be performed on a group of atoms. The \textit{computes} produce instantaneous values, using information about the atoms on the current time step. 

In LAMMPS there are more than 100 computes and chances are, they already have what you're looking for. If not, one might treat the data from other computes in some way to get the desired information. However, if there are no compute command that does the desired task, it is possible to create an own custom class and thereby expanding the LAMMPS library.  

In order to compute the normal forces acting on the sphere, we have written a custom compute class. The purpose of the class was to save the forces acting on atoms in one group from atoms of another group. In this section we will try do give brief instructions on how this was done.

{\color{editColor}[MAYBE AN ILLUSTRATIVE FIGURE HERE]}

\subsection{Find a similar compute}
Obviously, before writing any code we should know what we want the compute to calculate and how this should be done. 
Before starting off with a blank sheet in the editor, one should definitely search for similar computes in LAMMPS. This can potentially save hours of hard work!

For instance there is a compute named \textit{group/group}\footnote{\href{http://lammps.sandia.gov/doc/compute_group_group.html}{http://lammps.sandia.gov/doc/compute\_group\_group.html}} which computes the total energy and force interaction between two groups of atoms. 
This is almost what we want, but we need to know the total force acting on all atoms from atoms of other groups. {\color{editColor}It should also work with the Vashishta potential.}

Thus, there are minor modifications needed and because of the similarities we chose to make our compute a subclass of this one.


\subsection{Creating the class}
All computes in LAMMPS are subclasses of the class named  \textit{compute}. From this superclass they inherit a bunch of variables, functions and flags, which the user may decide to set. Functions are of course declared in the header file, while variables and flags are set in the source file. The source code of the \textit{group/group} compute is shown in Appendix \ref{groupgrouph}. Since we will be making a subclass of it, we change the \textit{private} property to \textit{protected} so that we have access to all the variables and functions.

We start out by creating a header file and decide upon a name for our class. We have chosen the name \textit{group/group/atom} since it is basically a per-atom version of the already existing compute \textit{group/group}. A complete header-file is shown in Listing \ref{groupGroupAtomHeader} and explained in detail below.

\lstinputlisting[caption={Header file of our new compute: \texttt{compute\_group\_group\_atom.h}.}, label={groupGroupAtomHeader}, language=c++, firstline=14, lastline=40]{../../LAMMPS/src/compute_group_group_atom.h}

\texttt{ComputeStyle} defines the command to be used in the LAMMPS input script to be \texttt{group/group/atom}, and the name to be \textit{ComputeGroupGroupAtom}. The name will be redundant to us. 

\texttt{nmax} is the number of atoms which are subject to a non zero force from atoms of another group at the current time step; it may vary.

\texttt{carray} is a two dimensional array containing the force on atoms in one group induced by atoms of another group. Its dimension will necessarily be \texttt{nmax} $\times$ 3.

\texttt{compute\_peratom()} and \texttt{pair\_contribution()} are functions which will be described below the corresponding source file. 



\lstinputlisting[caption={Source file of compute: \texttt{compute\_group\_group\_atom.cpp}.}, label={groupGroupAtomHeader}, language=c++, firstline=19, lastline=300]{../../LAMMPS/src/compute_group_group_atom.cpp}

In the constructor we set specific flags that LAMMPS uses to interpret what structure our data should have, and how to store them. 
We set the \texttt{peratom\_flag} to be \texttt{True}, which indicates that we desire to store some date for each atom. 
\texttt{size\_peratom\_cols} defines the number of data values to store for each atom. 
Also, we set the \texttt{scalar\_flag} and \texttt{vector\_flag} to \texttt{False}, since we do not wish to return a vector or scalar value.

Following the constructor is the destructor on line 40. Its only task is to free the memory occupied by the array once it is no longer needed.  

\texttt{compute\_peratom()} will resize the array to the number of atoms of concern, \texttt{nmax}. It does this using LAMMPS internal functions, which we will not care to describe here. Finally it calls upon functions{\huge  I ENDED HERE LAST TIME!}

{\color{editColor}Note that we should only compute the force for one of the groups. factor 2...}
\newpage
\section{Least squares regression}
The method of least squares aims to find parameters which  minimize the sum of the squared residuals, where residuals are the difference between observed values and the approximated value. We will use this method to approximate the slope of the surface of the substrate. This will be done by partitioning the system in a grid and do a plane approximation on each cell of the grid. In other words, we seek the coefficients in the plane equation
\begin{equation}
	z = ax + by + c
	\label{planeEquation}
\end{equation}
that minimizes the sum of the squared residuals
\begin{equation}
	S = \sum_{i=1}^{n} r_i^2 = \sum_{i=1}^{n} \lr{z_i - f(x_i, y_i, \vec{\beta)}}^2,
	\label{leastSquaresPlane}
\end{equation}
where $f(x_i,y_i,\vec{\beta})$ is the right hand side of the plane equation and $\vec{\beta}$ is the set of coefficients.
The minima has the property that the differential with respect to any coefficient is zero. 
\begin{equation}
	\frac{\partial S}{\partial \beta_j} 
	=  \sum_{i=1}^{n}\frac{\partial r_i^2}{\partial \beta_j} 
	=  \sum_{i=1}^{n}\frac{\partial r_i^2}{\partial r_i} \frac{\partial r_i}{\partial \beta_j} 
	= -2 \sum_{i=1}^{n}r_i\frac{\partial f(x_i,y_i, \vec{\beta})}{\partial \beta_j}
	= 0 , ~\forall ~\beta_j \in \vec{\beta}
\end{equation}
When approximating a plane we have three coefficients to account for: $a$, $b$ and $c$. This leaves us with the following set of equations:

\begin{align}
	&-2 \sum_{i=1}^{n} \lr{z_i - ax_i - by_i- c} \frac{\partial}{\partial a} \lr{ax_i + by_i + c} = 0 \\
	&-2 \sum_{i=1}^{n} \lr{z_i - ax_i - by_i- c} \frac{\partial}{\partial b} \lr{ax_i + by_i + c} = 0 \\
	&-2 \sum_{i=1}^{n} \lr{z_i - ax_i - by_i- c} \frac{\partial}{\partial c} \lr{ax_i + by_i + c} = 0,
\end{align}
 which corresponds to
 \begin{align}
 \hspace{25mm}&\sum_{i=1}^{n} z_ix_i& &=& &a\sum_{i=1}^{n} x_i^2& &+& &b\sum_{i=1}^{n} x_iy_i& &+& &c\sum_{i=1}^{n} x_i \hspace{15mm}\\
 &\sum_{i=1}^{n} z_iy_i& &=& &a\sum_{i=1}^{n} x_iy_i& &+& &b\sum_{i=1}^{n} y_i^2& &+& &c\sum_{i=1}^{n} y_i \\
 &\sum_{i=1}^{n} z_i& &=& &a\sum_{i=1}^{n} x_i& &+& &b\sum_{i=1}^{n} y_i& &+& &nc . 
 \end{align}
This can be expressed as a matrix equation.

\begin{equation}
\left[ \begin{array}{llc}
\displaystyle \sum x_i^2  &\displaystyle \sum x_iy_i &\displaystyle \sum x_i \\[1em]
\displaystyle \sum x_iy_i &\displaystyle \sum y_i^2  &\displaystyle \sum y_i \\[1em]
\displaystyle \sum x _i   &\displaystyle \sum y_i    &\displaystyle n
\end{array} \right]
\left[ \begin{array}{c}
\vspace{1mm}a\\[1em]
\vspace{1mm}b\\[1em]
\vspace{0.5mm}c
\end{array} \right]
=
\left[ \begin{array}{l}
\displaystyle \sum x_iz_i \\[1em] 
\displaystyle \sum y_iz_i \\[1em]
\displaystyle \sum z_i
\end{array} \right]
\label{linearSystemPlane}
\end{equation}
where we have omitted the indices to better readability.
Solving this linear system retrieves the optimal coefficients in the sense of the least squares method. 
The normal vector of the plane will be $\vec{n}=[a,b,1]$. 
This vector will be used to compute the size of the normal force. 
Since we know the average force on an atom in the chunk, and the normal vector from the approximated slope of the surface, we can compute the normal force simply as

\begin{equation}
	\vec{F_N} 
	= |\vec{F}|\cos{\theta}\frac{\vec{n}}{|\vec{n}|} .
\end{equation}
The cosine of the angle between the two vectors is given as
\begin{equation}
	\cos{\theta} = \frac{\vec{F}\cdot\vec{n}}{|\vec{F}| \cdot |\vec{n}|},
\end{equation} 
meaning that the normal force may be expressed as
\begin{equation} 
%	\vec{F_N} = \frac{\lr{\vec{F}\cdot\vec{n}}}{|\vec{n}|} \frac{\vec{n}}{|\vec{n}|} .\\
\vec{F_N} = \lr{\vec{F}\cdot\vec{n}} \frac{\vec{n}}{|\vec{n}|^2} .
\end{equation}
We will assume that the normal vector $\vec{n}$ is always in the same general direction as the average force, though obviously it may just as well point in the opposite direction and still be a normal vector to the plane. Programatically this was done in python as shown in Listing \ref{angleVecLine}.

\lstinputlisting[caption={Python function to compute the smallest angle between a vector and a line parallel to another vector. }, label={angleVecLine}, language=python, firstline=190, lastline=197]{../SiO2/large/pythonScripts/surface.py}



% ---------------------------------------------------------------------------- %

\appendix
\chapter{Source code}

\newpage
\section{compute\_group\_group.h}
\label{groupgrouph}
\lstinputlisting[language=c++, firstline=14, lastline=53]{../../LAMMPS/src/compute_group_group.h}

\newpage
\section{compute\_group\_group\_atom.h}
\lstinputlisting[language=c++, firstline=14, lastline=40]{../../LAMMPS/src/compute_group_group_atom.h}


\newpage
\section{compute\_group\_group\_atom.cpp}
\lstinputlisting[language=c++, firstline=19]{../../LAMMPS/src/compute_group_group_atom.cpp}


\chapter{Something}
\section{LAMMPS units}

\begin{table}[H]
	\begin{center}
		\caption{Unit convention of the \textit{metal} unit style in LAMMPS.}
		\begin{tabularx}{0.8\textwidth}{  @{\hspace{2em}} @{}XX@{} @{\hspace{2em}} }
			%Measurement			 & unit	\\
			\toprule
			Mass 					   & grams/mole\\ 
			\midrule
			Distance 		   		  & Angstroms\\
			\midrule
			Time 				 		& picoseconds\\
			\midrule
			Energy 			   		  & eV\\
			\midrule
			Velocity 		   		  & Angstroms/picosecond\\
			\midrule
			Force 			    	   & eV/Angstrom\\
			\midrule
			Torque 			    	  & eV\\
			\midrule
			Temperature    		  & Kelvin\\
			\midrule
			Pressure 		 		 & bars\\
			\midrule
			Dynamic viscosity & Poise\\
			\midrule
			Charge 					 & multiple of electron charge\\
			\midrule
			Dipole 					 & charge $\cdot$ Angstroms\\
			\midrule
			Electric field 		    & volts $/$ Angstrom\\
			\midrule
			Density 				& gram $/$ cm\^{}dim\\
			\bottomrule
		\end{tabularx}
		\label{tab:unitsMetal}
	\end{center}
\end{table}





\bibliographystyle{plain}
\bibliography{resources/Library.bib}


%Referances






\end{document}
```

Centering the front page
------------------------
By default, the maketitle command will generate the front page, but it will not be properly centered, but offset like any other page. To get around this, the best solution is to create a separate document, name it front-page.tex and add the following to it:

front-page.tex:
```latex
\documentclass[twoside,english]{uiofysmaster}
\geometry{a4paper,includeall,bindingoffset=0cm,margin=3cm,
            marginparsep=0cm,marginparwidth=0cm,top=2cm}

\author{Filip Henrik Larsen}
\title{\uppercase{The history of master thesises and other random gibberish}}
\date{June 2012}

\begin{document}

\begin{titlepage}
\maketitle
\end{titlepage}

\end{document}
